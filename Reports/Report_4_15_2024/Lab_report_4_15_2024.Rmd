---
title: "HCD Simulations Write Up"
author: "Audrey Fu Lab"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::html_document2: default
  bookdown::pdf_document2: default
number_sections: false
always_allow_html: true
header-includes:
  - \usepackage{float}
  - \usepackage{multirow}
  - \usepackage{lastpage}
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
bibliography: C:/Users/Bruin/Desktop/Research Assistantship/Thesis Proposal Defense/proposal_references.bib
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=10, fig.pos = "H")
#knitr::opts_chunk$set(list(echo = FALSE, eval = TALSE))
library(kableExtra)
library(knitr)
library(latex2exp)
library(gridExtra)
library(ggpubr)
library(ggthemes)
library(plyr)
basepath = 'C:/Users/Bruin/Documents/GitHub/HGRN_repo/Simulated Hierarchies/'
figpath = 'C:/Users/Bruin/Documents/GitHub/HGRN_repo/Reports/Report_4_15_2024/'

library(ggpubr)
# tab = read.csv(paste0(basepath, 'DATA/Toy_examples/Intermediate_examples/Results/MASTER_results_old_5_2_2024.csv'))


compile.to.pdf = FALSE

```

# Data Simulation {-}

### Simulating networks {-}
We adopt a top-down approach to simulate hierarchical networks, considering various simulation parameters such as graph sparsity, noise, and the architecture of the super-level graph(s), including small-world, scale-free, and random graph networks [@watts1998collective; @barabasi2003scale].

Our simulations focus on basic hierarchies comprising one or two hierarchical layers. Two-layer networks mirror classical community detection on graphs, where our aim is to recover the true community labels from a given graph. Meanwhile, three-layer networks present a more intricate scenario, where the bottom layer of the hierarchy contains two levels of community structure. Here, the top level corresponds to the nodes at the uppermost layer of the hierarchy, and the middle level consists of communities nested within the top-level communities. The objective with these networks is to identify both sets of community partitions.
	
In each hierarchy, for fully connected networks, we initiate by simulating $n_{\text{top}}$ top-level nodes, adhering to a directed small-world, random graph, or scale-free network architecture [@watts1998collective; @barabasi2003scale]. In cases where the network is disconnected, we simply simulate $n_{\text{top}}$ disconnected nodes. For networks with three hierarchical layers, we then generate a subnetwork of $n_{\text{middle}}$ nodes from each top-layer node, adhering to the network structure utilized at the top level. If the network is fully connected, we apply a probability $p_\text{between}$ to the nodes from different top-level communities being connected. 

The final step in all hierarchies is to generate the nodes in the observed (bottom) layer of the hierarchy. For each top-layer or middle-layer node, we generate a subnetwork of $n_{\text{bottom}}$ nodes under the same subnetwork structure as the previous layers, and we apply a probability $p_\text{between}$ for nodes from different communities to share an edge.

### Simulating gene expression {-}

Once we simulate a hierarchical graph, we utilize this hierarchy to generate the node-feature matrix, which depicts the expression of $N$ genes across $p$ samples. Here, $N$ denotes the number of nodes in the observed (bottom) layer of the hierarchy, and its range is governed by $a^{\ell+1}<N<a\times b^\ell$, where $\ell$ signifies the number of hierarchical layers.

We simulate the node-feature matrix using the topological order the observed level graph. We start by generating the features of nodes that have no parental input. We refer to these nodes as *origin* nodes. All origin nodes are simulated from a normal distribution with mean $0$ and standard deviation $\sigma$. All other nodes are simulated from a normal distribution centered at the mean of their parent nodes and with standard deviation $\sigma$. 

# Hierarchical Commuity Detection (HCD) Overview {-}

Our HCD method consists of two primary components:

  1. A graph autoencoder based on the architecture proposed by @salehi2019graph which utilizes graph attention layers such as those first indroduced by @velivckovic2017graph (See most recent version of pseudocode for details). In our applications, we incorporate multi-head attention in all encoder and decoder layers to expand model learning capacity. The graph autoencoder module takes a set of node attributes and an adjacency matrix defining the relationships between the node as input and learns a low dimensional embedding of the network and attributes. This embedding is then used to reconstruct the node attributes and adjacency matrix under a separate loss function for each.  
  
  2. The second component of HCD takes the embeddings generated by the autoencoder and applies a multilevel community detection process. This module is composed of $l$ fully connected layers, each representing a level in the hierarchy. Each layer's goal is to group the $k_{i-1}$ nodes from the previous level into $k_i$ communities. The number of layers in the hierarchy and the number of communities at each level are predefined parameters that need to be determined through other methods. 
  In our applications, we use the simulation truth for each parameter so that the communitiy detection module consists of $2$ layers where the first layer assigns the nodes at the bottom layer to the true number of communities at the middle layer. The second community detection layer assigns the nodes in the middle layer to communities in the top layer. 

# Datasets {-}
	
We consider three sets of hierarchical networks which represent varying difficulty levels for inference:
	

  1. **Complex networks** - used for final simulation assessment - **Table** \@ref(tab:tab1) - \@ref(tab:tab3) .
  
  2. **Intermediate networks** - used for investigative model tuning and performance assessment - **Table** \@ref(tab:tab4) .
  
  3. **Simple networks** - used for code implementation and debugging - **Table** \@ref(tab:tab5).

# Application to Intermediate Networks {-}


A comprehensive overview of the intermediate networks is presented in **Table** \@ref(tab:tab4). These networks are structured as three-layered systems, each characterized by small-world, scale-free, or random graph architectures. In contrast to the more intricate networks featured in the **Complex Networks** dataset, the intermediate networks exhibit a comparatively simpler configuration. Specifically, each network comprises $5$ super layer nodes, $15$ middle layer nodes, and $300$ bottom layer nodes. Our primary focus in utilizing this dataset is to examine the performance of the Hierarchical Community Detection (HCD) method when applied to three-layer networks. The smaller scale of these networks facilitates a more in-depth analysis of the detected communities within the middle and upper layers of their hierarchical structures. 

We apply the HCD method to each network separately using three options for the input graph corresponding to the nodes at the observed layer of the hierarchy:

  * The input graph is the true graph
  
  *  The input graph is the correlation matrix of the simulated gene expression
  
  *  The input graph is the correlation matrix of the simulated gene expression wherein correlations weaker than 0.2 are disregarded and set to zero
  
  *  The input graph is the correlation matrix of the simulated gene expression wherein correlations weaker than 0.5 are disregarded and set to zero
  
  *  The input graph is the correlation matrix of the simulated gene expression wherein correlations weaker than 0.7 are disregarded and set to zero
  

We also explore various combinations of weighting the loss function across each of the aforementioned input graphs. In all cases, we ensure that the predicted number of communities in the middle or top levels of the hierarchy aligns with the ground truth of the simulation.

### Evaluating performance {-}

We evaluate the performance of our HCD method using three graph-based clustering metrics:

   1. **homogeneity** evaluates the degree to which each predicted community contains only data points from a single true community, indicating how well the algorithm avoids mixing different groups. Thus, homogenity tends to be high if resolved communities contain only members of the same true community.
   
   2. **completeness** assesses the extent to which all data points that belong to the same true
community are correctly assigned to a single predicted community. Thus completeness is always high if all members of the same true communities end up in the same resolved community even if several true communities are allocated together. 
   
   3. **NMI** is a weighted average of the previous two metrics. 

For each simulation, we configure the number of communities in the middle and upper layers of the hierarchy to match the true count in each layer. Then, we evaluate the community predictions of the Hierarchical Community Detection (HCD) algorithm at these levels against the actual communities using three metrics. As a baseline, we employ the Louvain method, which utilizes hierarchical graph partitioning to maximize modularity, resulting in a single set of resolved communities. These resolved communities may align with the middle, upper, or a combination of both layers in the true hierarchy. Thus, we compute the performance metrics of the communities identified by the Louvain method against the true communities at both the upper and middle levels of the hierarchy.


### Examples {-}

In examples 1-10 we use the true graph as the input graph and we assess the quality of performance primarily on the ability to infer communities for the top layer.

**Example 1-3** 
Examples 1-2 illustrate the impact of the attribute reconstruction loss. Example 3 . Specifically, Example 1 demonstrates the negative effects of overemphasizing the attribute reconstruction loss by setting its parameter too high, which dilutes the impact of graph reconstruction. This imbalance leads to inaccuracies in the reconstructed graph. Example 2 shows that when graph reconstruction is given equal priority to other loss components, HCD can resolve the correct communities. In Example 3, the modularity loss component is turned off by setting its value to zero to investigate the importance of modularity loss component on performance.

In all three examples, we apply HCD to the 3-layer, disconnected, small-world network in the intermediate networks dataset. In addition, all three examples use the same number of autoencoder layers, settings for clustering loss component, and 10 attention heads. All parameter settings for these examples are detailed in **table** \@ref(tab:ex123params). Specific outcomes for each example are discussed in greater detail in the Results section. 

 

**Examples 4-5**

# Results {-}

Previously we applied our HCD method to all complex and intermediate datasets looking at various parameters such as the input graph and some initial test values for loss hyperparameters. Our previous findings are outlined in the lab report from 3/13/2024 and pointed out several issues that remain to be addressed. Below, we address these points in detail and provide supporting examples from applying HCD to networks in the Intermediate Networks dataset (**Table** \@ref(tab:tab4)).

### An additional loss component is needed to help further reduce the tendency of HCD to combine smaller communities into super-communities. {-} 

  * We have since implemented a hierarchical adaptation of the Kmeans approach which aims to ensure members clustered to the same community have the smallest possible dissimilarity. See the latest update of the HCD pseudo code to view the specific mathematical details. 

### How should we assess performance when comparing the Louvain method and our HCD method? {-} 

  * Louvain uses a heuristic hierarchical community partitioning approach to find the communities that maximize modularity within a local greedy search of the space of possible partitions. The predicted communities are the final community assignments that arise when no additional assignment changes can improve the modularity - when a local optimum of modularity has been achieved. This leads to a single set of community predictions which may represent either the top layer of the true hierarchy or it may represent one of the middle layers. It may also be a blend of middle and top layers. As a result, we will compare the predictions from the Louvain method to the truth for both the middle and top layer communities. 
  For our HCD method, we set the community detection module to mirror the simulation truth (i.e 2 layers corresponding to $15$ middle layer communities and $5$ top layer communities). Therefore, HCD provides two sets of community predictions corresponding to the two upper layers in the hierarchy. However, there is no assurance that the predicted communities will accurately align with the hierarchical structure they're intended to represent.
  To evaluate performance, we compare the predicted middle-layer communities against the true community assignments for both the middle and top layers. Additionally, we compare the predicted top-layer communities to the true top-layer assignments. This approach generates three sets of performance metrics, which we can then qualitatively compare against the results from the Louvain method.
  
### Settings for tuning parameters {-}
  
**Examples 1 - 2; When the attribute reconstruction loss is too large:** To ensure that the loss for graph reconstruction isn't overshadowed, we find it necessary to downweight the tuning parameters for the attribute reconstruction, modularity, and clustering loss components. We demonstrate this by applying HCD to a disconnected small-world intermediate network, using the true adjacency matrix as input. In this network, the communities at the top layer are completely isolated from each other.
  If the attribute reconstruction loss is set too high, the model can generate artificial connections in the graph. As shown in **Figure** \@ref(fig:example1fig1), HCD has divided the original graph into two separate subgraphs by creating false links between the first three communities and the last two. This results in distinct blocks in the reconstructed adjacency matrix. Additionally, in **Figure** \@ref(fig:example1fig2), you can see that these false connections cause the affected nodes to be incorrectly assigned to the same top-level communities. This occurs because the high attribute reconstruction loss encourages the model to form connections that aid in attribute prediction, even if they do not reflect the true graph structure (**Figure** \@ref(fig:example1fig2)). The PCA plot in **Figure** \@ref(fig:example1fig4) indicates that the model is essentially grouping nodes based on their similarity along the first two principle dimensions of attribute space, which leads to these inaccurate connections.
  To correct this, we downweight the tuning parameter for the attribute reconstruction component, giving graph reconstruction a higher priority during training (**Figure** \@ref(fig:example2fig1)). This adjustment leads to a more accurate representation of the adjacency matrix and better predictions for the top-layer communities (**Figures** \@ref(fig:example2fig2) - \@ref(fig:example2fig3) ; **Table** \@ref(tab:example123perf)).
  
**Modularity is necessary:** 
Our HCD method uses two loss components to assess the quality of inferred communities: (i) modularity loss and (ii) clustering loss. These two components approach community structure from different angles. Modularity loss evaluates the quality of clusters based on the input graph, ensuring that communities have more internal connections than external ones. Clustering loss, however, focuses on node features and aims to form communities where the nodes are as similar as possible, measured by their Euclidean distance to the community centroid.

In Example 3, we set the modularity tuning parameter to zero to examine whether clustering loss alone can resolve community assignments. Our results show that both metrics are needed for the best outcome (**Figures** \@ref(fig:example3fig1) - \@ref(fig:example3fig3); **Table** \@ref(tab:example123perf)). Turning off modularity leads to overgrouping of communities 1 and 3 (**Figure** \@ref(fig:example3fig2)), likely because of their similarity along the first principal dimension of the attribute space (**Figure** \@ref(fig:example3fig3)). This suggests that modularity plays a crucial role in separating clusters that might be structurally different but have similar feature patterns. 

**Do tuning parameter settings hold for more complicated networks?** In Example 4, we extend the setup from Example 2 by applying HCD to the more complex fully connected small-world intermediate network to evaluate whether the parameters from the earlier example still hold under more complicated structural relationships.  (**Table** \@ref(tab:ex45params)). As shown in **Table** \@ref(tab:example45perf), prediction performance of HCD for top-level communities is lower than in Example 2, which is understandable given the increased structural complexity of this network. Despite this drop in performance, HCD outperforms the Louvain method with a NMI score of $72.8\%$, compared to Louvain's $63.8\%$. 

In this example, the Louvain method achieves high homogeneity ($79.1\%$) but lower completeness ($53.4\%$), indicating that the top-layer communities are being broken into smaller, internally consistent, groups. This imbalance results in a lower overall NMI (see Figure \@ref(fig:example4fig1)).

In contrast, HCD achieves a better balance between these two metrics, with homogeneity at $72.5\%$ and completeness at $73.2\%$ (**Figure** \@ref(fig:example4fig2); **Table** \@ref(tab:example45perf)). This balance contributes to HCD's higher overall NMI. However, the reduced NMI for HCD compared to its performance in Example 2 is largely due to several misallocated nodes. This misallocation is likely caused by greater heterogeneity in the top-layer communities within this more complex network, as illustrated by the PCA presented in **Figure** \@ref(fig:example4fig3).

Similarly, in Example 5, we replicate the setup from Example 3 - turning off modularity - while applying HCD to the same fully connected small-world network. **Table** \@ref(tab:example45perf) shows that turning off modularity results in reduced performance, with a slightly lower NMI score of $69.2\%$. This further validates our earlier finding that modularity is required to achieve optimal results.

### Should parent (origin) nodes be simulated from the same or different distributions? {-}

When simulating the networks for the datasets, we use the hierarchy to generate the nodes at the bottom/observed layer under a specific directed graph structure (small world, scale free, random graph). This allows for nodes in the bottom layer to be traced through the levels of the hierarchy to their respective communities in each level. The simualted gene expression for the nodes in the observed layer is then generated using the topological order of the network relating the nodes at this level. Under this framework, nodes which have no parents are generated first from a normal distribution with zero mean and fixed variance 

\[ N_{i,k} \sim N(0, \sigma) \]

Here $N_{i,k}$ is the $i^{th}$ parent node in the $k^{th}$ middle layer communitity. This framework causes all node communities to have some similarity because they all originate from the same parents. This is clearly illustrated in PC space where all communities diverge from a central location (**Figure** \@ref(fig:example6fig1)). This similarity among communities may underlay poorer performance for HCD, especially on more complicated networks. Therefore in Examples 6-7, we test the performance of HCD on the disconnect and fully connected small world networks when the networks are simulated by generating a different distribution for each parent node \@ref(tab:ex67params)

\[ N_{i,k} \sim N(\mu_k, \sigma) \]
  
Simulating the hierarchy under this framework allows the parent nodes belonging to each community to have a unique distribution and corresponds to greater separability along the first principle dimension of the attribute space **Figure** \@ref(fig:example6fig2). 

Despite greater separation, HCD performance (using the same parameter settings as in Ex.1-3) was much worse for the disconnected small world network simulated in this way (**Table** \@ref(tab:example67perf)). As can be seen in **Figure** \@ref(fig:example6fig3), HCD produces a result similar to what we experienced in Example 3 where communities at the top layer are grouped into super-communities leading to higher completeness ($84\%$) but much lower homogeneity ($51.7\%$) when compared to the Louvain method applied to the same network (homogeneity $100\%$, completeness $70.5\%$). This in part could be due to the parameter settings used previously being no longer applicable because the nature of how the data are simulated has been changed. This is supported by larger absolute loss for the clustering component - potentially washing out the graph reconstruction loss. This suggests this component may need to be downweighted further. An alternative explanation is that the model does not have enough learning capability to capture the communities correctly. We explore both possibilities further:

  * **Clustering Loss Downweighted Further** - In Example 7, we downweight the clustering loss even further so that the clustering loss for the middle layer is $\lambda_{middle} = 0.0001$ and for the top layer is $\lambda_{top} = 0.00001$. As shown in **Table** \@ref(tab:example67perf), this greatly improved performance for HCD with NMI now comparable to Louvain method applied to the same network. 
  
  
### Points to investigate

  * Simulating origina nodes from different distributions leads to greater separability of top layer clusters. Simulations going forward should focus on applications to networks constructed under this framework as it provides an easier case for investigating model behavior
  
  * All examples presented herein were done using the true graph as the input graph. This is not realistic in a practical setting. Therefore, we need to re-investigate these example using an estimated input graph such as the $r < 0.5$ cutoff graph as an estimate of the true network. Understanding model behavior in this setting is important to determine efficacy under true application settings. 
  
  * HCD seems to have an unsual tendency to group distance node clusters despite the clustering loss component trying to minimize within cluster distances. Need to look at model embeddings to determine why this is occuring. For example, is HCD grouping distinct clusters because these clusters are somehow ending up close in embedding space?

# Tables

```{r tab1, eval=T, echo=F, message=F, warning=F}

complex_net_stats = read.csv('C:/Users/Bruin/Documents/GitHub/HGRN_repo/Simulated Hierarchies/DATA/network_statistics.csv')[,-1]

complex_net_stats$modularity_top = round(complex_net_stats$modularity_top, 3)
complex_net_stats$avg_node_degree_top = round(complex_net_stats$avg_node_degree_top, 3)
complex_net_stats$avg_connect_within_top = round(complex_net_stats$avg_connect_within_top, 3)
complex_net_stats$avg_connect_between_top = round(complex_net_stats$avg_connect_between_top, 3)
complex_net_stats$modularity_middle = round(complex_net_stats$modularity_middle, 3)
complex_net_stats$avg_node_degree_middle = round(complex_net_stats$avg_node_degree_middle, 3)
complex_net_stats$avg_connect_within_middle = round(complex_net_stats$avg_connect_within_middle, 3)
complex_net_stats$avg_connect_between_middle = round(complex_net_stats$avg_connect_between_middle, 3)




if(compile.to.pdf){
  df = rbind.data.frame(c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)'), complex_net_stats)
  kable(t(df[1:9,]), format = 'latex', digits = 2, row.names = F, col.names = c('Value', paste0('Network', c(1:8))),
                                                                                    booktabs = T,
      caption = 'Summary statistics for all small world networks in the complex networks datset')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 9)%>%column_spec(1, '6em')%>%column_spec(2:9, '4em')
}else{
  
  df = complex_net_stats
  colnames(df) = c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)')
kable(df[1:8,], format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Summary statistics for all small world networks in the complex networks datset')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}



```


\newpage
```{r tab2, eval = T, echo=F, message=F, warning=F}


if(compile.to.pdf){
  kable(t(df[c(1, 10:17),]), format = 'latex', digits = 2, row.names = F, col.names = c('Value', paste0('Network', c(1:8))),
                                                                                  booktabs = T,
     caption = 'Summary statistics for all scale free networks in the complex networks datset')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 9)%>%column_spec(1, '6em')%>%column_spec(2:9, '4em')
}else{
  kable(df[c(9:16),], format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Summary statistics for all scale free networks in the complex networks datset')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}




```


\newpage
```{r tab3, eval = T, echo=F, message=F, warning=F}


if(compile.to.pdf){
  kable(t(df[c(1, 18:25),]), format = 'latex', digits = 2, row.names = F, col.names = c('Value', paste0('Network', c(1:8))),
                                                                                    booktabs = T,
      caption = 'Summary statistics for all random graph networks in the complex networks datset')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 9)%>%column_spec(1, '6em')%>%column_spec(2:9, '4em')
}else{
  kable(df[c(17:24),], format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Summary statistics for all random graph networks in the complex networks datset')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}


```


\newpage
```{r tab4, eval = T, echo=F, message=F, warning=F}

inter_net_stats = read.csv('C:/Users/Bruin/Documents/GitHub/HGRN_repo/Simulated Hierarchies/DATA/Toy_examples/Intermediate_examples/OLD_DATA_5_2_2024/intermediate_examples_network_statistics.csv')[,-1]

inter_net_stats$modularity_top = round(inter_net_stats$modularity_top, 3)
inter_net_stats$avg_node_degree_top = round(inter_net_stats$avg_node_degree_top, 3)
inter_net_stats$avg_connect_within_top = round(inter_net_stats$avg_connect_within_top, 3)
inter_net_stats$avg_connect_between_top = round(inter_net_stats$avg_connect_between_top, 3)
inter_net_stats$modularity_middle = round(inter_net_stats$modularity_middle, 3)
inter_net_stats$avg_node_degree_middle = round(inter_net_stats$avg_node_degree_middle, 3)
inter_net_stats$avg_connect_within_middle = round(inter_net_stats$avg_connect_within_middle, 3)
inter_net_stats$avg_connect_between_middle = round(inter_net_stats$avg_connect_between_middle, 3)





if(compile.to.pdf){
  df = rbind.data.frame(c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)'), inter_net_stats)
  kable(t(df), format = 'latex', digits = 2, row.names = F, col.names = c('Value', paste0('Network', c(1:6))),
                                                                                    booktabs = T,
      caption = 'Summary statistics for intermediate difficulty simulated networks.')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
    df = inter_net_stats
    colnames(df) = c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)')
  kable(df, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Summary statistics for intermediate difficulty simulated networks.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}




```


\newpage
```{r tab5, eval = T, echo=F, message=F, warning=F}

toy_net_stats = read.csv('C:/Users/Bruin/Documents/GitHub/HGRN_repo/Simulated Hierarchies/DATA/Toy_examples/toy_examples_network_statistics.csv')[,-1]

toy_net_stats$modularity_top = round(toy_net_stats$modularity_top, 3)
toy_net_stats$avg_node_degree_top = round(toy_net_stats$avg_node_degree_top, 3)
toy_net_stats$avg_connect_within_top = round(toy_net_stats$avg_connect_within_top, 3)
toy_net_stats$avg_connect_between_top = round(toy_net_stats$avg_connect_between_top, 3)
toy_net_stats$modularity_middle = round(toy_net_stats$modularity_middle, 3)
toy_net_stats$avg_node_degree_middle = round(toy_net_stats$avg_node_degree_middle, 3)
toy_net_stats$avg_connect_within_middle = round(toy_net_stats$avg_connect_within_middle, 3)
toy_net_stats$avg_connect_between_middle = round(toy_net_stats$avg_connect_between_middle, 3)




if(compile.to.pdf){
  
  df = rbind.data.frame(c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)'), toy_net_stats)
  kable(t(df), format = 'latex', digits = 2, row.names = F, col.names = c('Value', paste0('Network', c(1:4))),
                                                                                    booktabs = T,
      caption = 'Summary statistics for simple simulated networks. These networks contain fewer than 100 nodes at the observed level and only cover small world subgraph architecture')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  
  df = toy_net_stats
  colnames(df) = c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)')
  kable(df, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Summary statistics for simple simulated networks. These networks contain fewer than 100 nodes at the observed level and only cover small world subgraph architecture.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}



```


\newpage
```{r tab6, echo=F, eval = F, message=F, warning=F}

grid = expand.grid(`Input Graph` = unique(tab$input_graph),
                   `Graph Recon. Loss` = c('1 = on', '0 = off'),
                   `Attr. Recon. Loss` = c('False (on)', 'True (off)'),
                   `Modularity Weight` = c('1 = on', '0 = off'),
                   `Clust. Weight` = c('1 (middle), 1 (top)', '0.1 (middle), 1e-4 (top)'))


if(compile.to.pdf){
  kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
      caption = 'Simulation settings for intermediate difficulty networks. Each row represents a single simulation scenario applied to all 6 networks in the intermediate networks dataset.')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(grid, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Simulation settings for intermediate difficulty networks. Each row represents a single simulation scenario applied to all 6 networks in the intermediate networks dataset.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}



```



```{r ex123params, echo=F, eval = T, message=F, warning=F, results ='asis'}

ex1.params = read.csv(paste0(figpath, 'example1_output/param_settings.csv'), row.names = 1)
ex1.params = rbind.data.frame(ex1.params, c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Small World/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(0, \\sigma)$'),
                              c('Network ID:', '3L-SMW-ComDist-Inter'))
ex2.params = read.csv(paste0(figpath, 'example2_output/param_settings.csv'), row.names = 1)
ex2.params = rbind.data.frame(ex2.params, c('Input Graph', 'True Graph'), 
                              c('Layers', 3),
                              c('Network Type', 'Small World/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(0, \\sigma)$'),
                              c('Network ID:', '3L-SMW-ComDist-Inter'))
ex3.params = read.csv(paste0(figpath, 'example3_output/param_settings.csv'), row.names = 1)
ex3.params = rbind.data.frame(ex3.params, c('Input Graph', 'True Graph'), 
                              c('Layers', 3),
                              c('Network Type', 'Small World/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(0, \\sigma)$'),
                              c('Network ID:', '3L-SMW-ComDist-Inter'))


cn = colnames(ex1.params)
colnames(ex1.params) = c('Parameter', "Example 1")
ctab = cbind(ex1.params, ` ` = rep('', 17), `Examples 2` = ex2.params[,-1], `Examples 3` = ex3.params[,-1])


if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'HCD settings for Examples 1 - 3.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 14)
}

```



```{r ex45params, echo=F, eval = T, message=F, warning=F}

ex4.params = read.csv(paste0(figpath, 'example4_output/param_settings.csv'), row.names = 1)
ex4.params = rbind.data.frame(ex4.params, c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Small World/Fully Connected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(0, \\sigma)$'),
                              c('Network ID:', '3L-SMW-CommDist-Inter'))
ex5.params = read.csv(paste0(figpath, 'example5_output/param_settings.csv'), row.names = 1)
ex5.params = rbind.data.frame(ex5.params, c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Small World/Fully Connected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(0, \\sigma)$'),
                              c('Network ID:', '3L-SMW-CommDist-Inter'))



cn = colnames(ex4.params)
colnames(ex4.params) = c('Parameter', "Example 4")
ctab = cbind(ex4.params, ` ` = rep('', 17), `Example 5` = ex5.params[,-1])


if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'HCD settings for Examples 4 - 5.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 14)
}

```



```{r ex67params, echo=F, eval = T, message=F, warning=F}

ex6.params = read.csv(paste0(figpath, 'example6_output/param_settings.csv'), row.names = 1)
ex6.params = rbind.data.frame(ex6.params, c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Small World/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', '3L-SMW-DiffDist-Inter'))
ex7.params = read.csv(paste0(figpath, 'example7_output/param_settings.csv'), row.names = 1)
ex7.params = rbind.data.frame(ex7.params, c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Small World/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', '3L-SMW-DiffDist-Inter'))



cn = colnames(ex6.params)
colnames(ex6.params) = c('Parameter', "Example 6")
ctab = cbind(ex6.params, ` ` = rep('', 17), `Example 7` = ex7.params[,-1])


if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'HCD settings for Examples 6 - 7.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 14)
}

```



```{r example123perf, echo=F, eval = T, message=F, warning=F}

ex1.tab = read.csv(paste0(figpath, 'example1_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
ex2.tab = read.csv(paste0(figpath, 'example2_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
ex3.tab = read.csv(paste0(figpath, 'example3_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
cn = colnames(ex1.tab)
ctab = cbind(ex1.tab, ` ` = rep('', 5), ex2.tab[,-1], ex3.tab[,-1])


if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'Performance metrics for Louvain method and HCD in Examples 1 - 3. For details regarding parameter settings see Examples 1 - 3 under section <i>Examples</i>. All results are for the disconnected small-world intermediate network.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)%>%add_header_above(c(' ' = 1, "Example 1" = 4, "Example 2" = 3, 'Example 3' = 3))
}



```




```{r example45perf, echo=F, eval = T, message=F, warning=F}

ex4.tab = read.csv(paste0(figpath, 'example4_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
ex5.tab = read.csv(paste0(figpath, 'example5_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
cn = colnames(ex4.tab)
ctab = cbind(ex4.tab, ` ` = rep('', 5), ex5.tab[,-1])


if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'Performance metrics for Louvain method and HCD in Examples 4-5. For details regarding parameter settings see Examples 4-5 under section <i>Examples</i>. All results are for the fully connected small-world intermediate network.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 14)%>%add_header_above(c(' ', "Example 4" = 3, "Example 5" = 4))
}



```



```{r example67perf, echo=F, eval = T, message=F, warning=F}

ex6.tab = read.csv(paste0(figpath, 'example6_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
ex7.tab = read.csv(paste0(figpath, 'example7_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
cn = colnames(ex6.tab)
ctab = cbind(ex6.tab, ` ` = rep('', 5), ex7.tab[,-1])


if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'Performance metrics for Louvain method and HCD in Examples 6-7. For details regarding parameter settings see Examples 4-5 under section <i>Examples</i>. All results are for the fully connected small-world intermediate network.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 14)%>%add_header_above(c(' ', "Example 6" = 3, "Example 7" = 4))
}



```

# Figures 


```{r example1fig1, echo=FALSE, message=F, warning=F, fig.height=5, fig.width=10, fig.cap = 'The true and reconstructed adjacency matrix for Example 1 application of HCD to the disconnected small-world intermediate network. Left: the reconstructed adjacency matrix after 500 training epochs. Right: The input graph and true adjacency matrix.'}
include_graphics(paste0(figpath, 'example1_output/smw_disc_3_layer_epoch_500_Adjacency_maps.png'))

```


```{r example1fig2, echo=FALSE, message=F, warning=F, fig.height=5, fig.width=10, fig.cap = 'The middle and top layer community predictions corresponding to Example 1 - application of HCD to disconnected small-world intermeidate network.'}
include_graphics(paste0(figpath, 'example1_output/best_iteration_303epoch_303_heatmaps.png'))
```

```{r example1fig3, echo=FALSE, message=F, warning=F, fig.align='center', fig.height=8, fig.width=15, fig.cap = 'Example 1 training loss curves.'}
include_graphics(paste0(figpath, 'example1_output/500_epochs_training_loss.png'))
```


```{r example1fig4, echo=FALSE, message=F, warning=F, fig.height=8, fig.width=10, fig.cap = 'A plot of the nodes in the first three prinicple dimensions of the attribute space. Colors correspond to the predicted top layer community assignments corresponding the application in Example 1 for the \"best\" performing epoch.'}
include_graphics(paste0(figpath, 'example1_output/Top Layer_3D_PCA_Plot.png'))
```


```{r example2fig1, echo=FALSE, message=F, warning=F, fig.align='center', fig.height=8, fig.width=10, fig.cap = 'Example 2 training loss curves.'}
include_graphics(paste0(figpath, 'example2_output/500_epochs_training_loss_curves.png'))
```


```{r example2fig2, echo=FALSE, message=F, warning=F, fig.height=8, fig.width=10, fig.cap = 'The true and reconstructed adjacency matrix for Example 2 application of HCD to the disconnected small-world intermediate network. Left: the reconstructed adjacency matrix after 500 training epochs. Right: The input graph and true adjacency matrix.'}
include_graphics(paste0(figpath, 'example2_output/smw_disc_3_layer_epoch_500_Adjacency_maps.png'))
```


```{r example2fig3, echo=FALSE, message=F, warning=F, fig.height=8, fig.width=10, fig.cap = 'The middle and top layer community predictions corresponding to Example 2 - application of HCD to disconnected small-world intermeidate network with downweighted attribute reconstruction loss'}
include_graphics(paste0(figpath, 'example2_output/best_iteration_476epoch_476_heatmaps.png'))
```


```{r example3fig1, echo=FALSE, message=F, warning=F, fig.height=8, fig.width=10, fig.cap = 'The true and reconstructed adjacency matrix for Example 3 - application of HCD to the disconnected small-world intermediate network. Left: the reconstructed adjacency matrix after 500 training epochs. Right: The input graph and true adjacency matrix.'}
include_graphics(paste0(figpath, 'example3_output/best_iteration_124epoch_124_Adjacency_maps.png'))
```


```{r example3fig2, echo=FALSE, message=F, warning=F, fig.height=8, fig.width=10, fig.cap = 'The middle and top layer community predictions corresponding to Example 3 - application of HCD to disconnected small-world intermeidate network with downweighted attribute reconstruction loss'}
include_graphics(paste0(figpath, 'example3_output/best_iteration_124epoch_124_heatmaps.png'))
```


```{r example3fig3, echo=FALSE, message=F, warning=F, fig.height=8, fig.width=10, fig.cap = 'A plot of the nodes in the first three prinicple dimensions of the attribute space. Colors correspond to the predicted top layer community assignments corresponding the application in Example 1 for the \"best\" performing epoch.'}
include_graphics(paste0(figpath, 'example3_output/Top Layer_3D_PCA_Plot.png'))
```

```{r example4fig1, echo=FALSE, message=F, warning=F, fig.height=8, fig.width=10, fig.cap = 'Louvain community predictions compared to the true middle and top layer communities for the fully connected small-world intermediate network'}
include_graphics(paste0(figpath, 'example4_output/Louvain_results.png'))
```

```{r example4fig2, echo=FALSE, message=F, warning=F, fig.height=8, fig.width=10, fig.cap = 'The middle and top layer community predictions corresponding to Example 4 - application of HCD to the fully-connected, small-world intermeidate network.'}
include_graphics(paste0(figpath, 'example4_output/best_iteration_187epoch_187_heatmaps.png'))
```


```{r example4fig3, echo=FALSE, message=F, warning=F, fig.height=8, fig.width=10, fig.cap = 'A plot of the nodes in the first three prinicple dimensions of the attribute space for the fully connected, small-world intermeidate netowrk. Colors correspond to the predicted top layer community assignments corresponding the application in Example 4 for the \"best\" performing epoch.'}
include_graphics(paste0(figpath, 'example4_output/Top Layer_3D_PCA_Plot.png'))
```

```{r example6fig1, eval = T, echo=FALSE, message=F, warning=F, fig.height=10, fig.width=12, fig.align='center', fig.cap = 'A plot of the nodes in the first three prinicple dimensions of the attribute space for the disconnected, small-world intermeidate netowrk. Colors correspond to the true top layer communities. In this network, orign nodes are simulated from the same distribution resulting in all communities originating from a central point in the PC space. Red points represent parent nodes'}
include_graphics(paste0(figpath, 'example6_output/3D_PCA_GTCommon_dist.png'))
```



```{r example6fig2, eval = T, echo=FALSE, message=F, warning=F, fig.height=10, fig.width=12, fig.align='center', fig.cap = 'A plot of the nodes in the first three prinicple dimensions of the attribute space for the disconnected, small-world intermeidate network. In this network, orign nodes are simulated from a unique distribution resulting in all communities originating at distinct points in the PC space. Red points represent parent nodes'}
include_graphics(paste0(figpath, 'example6_output/3D_PCA_GT.png'))
```



```{r example6fig3, eval = T, echo=FALSE, message=F, warning=F, fig.height=8, fig.width=10, fig.cap = 'A plot of the nodes in the first three prinicple dimensions of the attribute space for the fully connected, small-world intermeidate netowrk. Colors correspond to the predicted top layer community assignments corresponding the application in Example 6 for the \"best\" performing epoch.'}
include_graphics(paste0(figpath, 'example6_output/Top Layer_3D_PCA_Plot.png'))
```



```{r example6fig4, eval = T, echo=FALSE, message=F, warning=F, fig.height=10, fig.width=12, fig.align='center', fig.cap = 'Example 6 training loss curves.'}
include_graphics(paste0(figpath, 'example6_output/training_loss_curves.png'))
```






# References
\bibliographystyle{unsrt}
	\bibliography{C:/Users/Bruin/Desktop/Research Assistantship/Thesis Proposal Defense/proposal_references.bib}

\newpage
\section*{References}
