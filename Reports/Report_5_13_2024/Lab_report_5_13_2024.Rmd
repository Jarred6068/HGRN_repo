---
title: "HCD Simulations Write Up"
author: "Audrey Fu Lab"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::html_document2: default
  bookdown::pdf_document2: default
number_sections: false
always_allow_html: true
header-includes:
  - \usepackage{float}
  - \usepackage{multirow}
  - \usepackage{lastpage}
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
bibliography: C:/Users/Bruin/Desktop/Research Assistantship/Thesis Proposal Defense/proposal_references.bib
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=10, fig.pos = "H")
#knitr::opts_chunk$set(list(echo = FALSE, eval = TALSE))
library(kableExtra)
library(knitr)
library(latex2exp)
library(gridExtra)
library(ggpubr)
library(ggthemes)
library(plyr)
basepath = 'C:/Users/Bruin/Documents/GitHub/HGRN_repo/Simulated Hierarchies/'
figpath = 'C:/Users/Bruin/Documents/GitHub/HGRN_repo/Reports/Report_5_13_2024/'

library(ggpubr)
# tab = read.csv(paste0(basepath, 'DATA/Toy_examples/Intermediate_examples/Results/MASTER_results_old_5_2_2024.csv'))


compile.to.pdf = FALSE

```

# Data Simulation {-}

### Simulating networks {-}
We adopt a top-down approach to simulate hierarchical networks, considering various simulation parameters such as graph sparsity, noise, and the architecture of the super-level graph(s), including small-world, scale-free, and random graph networks [@watts1998collective; @barabasi2003scale].

Our simulations focus on basic hierarchies comprising one or two hierarchical layers. Two-layer networks mirror classical community detection on graphs, where our aim is to recover the true community labels from a given graph. Meanwhile, three-layer networks present a more intricate scenario, where the bottom layer of the hierarchy contains two levels of community structure. Here, the top level corresponds to the nodes at the uppermost layer of the hierarchy, and the middle level consists of communities nested within the top-level communities. The objective with these networks is to identify both sets of community partitions.
	
In each hierarchy, for fully connected networks, we initiate by simulating $n_{\text{top}}$ top-level nodes, adhering to a directed small-world, random graph, or scale-free network architecture [@watts1998collective; @barabasi2003scale]. In cases where the network is disconnected, we simply simulate $n_{\text{top}}$ disconnected nodes. For networks with three hierarchical layers, we then generate a subnetwork of $n_{\text{middle}}$ nodes from each top-layer node, adhering to the network structure utilized at the top level. If the network is fully connected, we apply a probability $p_\text{between}$ to the nodes from different top-level communities being connected. 

The final step in all hierarchies is to generate the nodes in the observed (bottom) layer of the hierarchy. For each top-layer or middle-layer node, we generate a subnetwork of $n_{\text{bottom}}$ nodes under the same subnetwork structure as the previous layers, and we apply a probability $p_\text{between}$ for nodes from different communities to share an edge.

### Simulating gene expression {-}

Once we simulate a hierarchical graph, we utilize this hierarchy to generate the node-feature matrix, which depicts the expression of $N$ genes across $p$ samples. Here, $N$ denotes the number of nodes in the observed (bottom) layer of the hierarchy, and its range is governed by $a^{\ell+1}<N<a\times b^\ell$, where $\ell$ signifies the number of hierarchical layers.

We simulate the node-feature matrix using the topological order the observed level graph. We start by generating the features of nodes that have no parental input. We refer to these nodes as *origin* nodes. All origin nodes are simulated from a normal distribution with mean $0$ and standard deviation $\sigma$. All other nodes are simulated from a normal distribution centered at the mean of their parent nodes and with standard deviation $\sigma$. 

# Hierarchical Commuity Detection (HCD) Overview {-}

Our HCD method consists of two primary components:

  1. A graph autoencoder based on the architecture proposed by @salehi2019graph which utilizes graph attention layers such as those first indroduced by @velivckovic2017graph (See most recent version of pseudocode for details). In our applications, we incorporate multi-head attention in all encoder and decoder layers to expand model learning capacity. The graph autoencoder module takes a set of node attributes and an adjacency matrix defining the relationships between the node as input and learns a low dimensional embedding of the network and attributes. This embedding is then used to reconstruct the node attributes and adjacency matrix under a separate loss function for each.  
  
  2. The second component of HCD takes the embeddings generated by the autoencoder and applies a multilevel community detection process. This module is composed of $l$ fully connected layers, each representing a level in the hierarchy. Each layer's goal is to group the $k_{i-1}$ nodes from the previous level into $k_i$ communities. The number of layers in the hierarchy and the number of communities at each level are predefined parameters that need to be determined through other methods. 
  In our applications, we use the simulation truth for each parameter so that the communitiy detection module consists of $2$ layers where the first layer assigns the nodes at the bottom layer to the true number of communities at the middle layer. The second community detection layer assigns the nodes in the middle layer to communities in the top layer. 

# Datasets {-}
	
We consider three sets of hierarchical networks which represent varying difficulty levels for inference:
	

  1. **Complex networks** - used for final simulation assessment - **Table** \@ref(tab:tab1) - \@ref(tab:tab3) .
  
  2. **Intermediate networks** - used for investigative model tuning and performance assessment - **Table** \@ref(tab:tab4) .
  
  3. **Simple networks** - used for code implementation and debugging - **Table** \@ref(tab:tab5).

# Application to Intermediate Networks {-}


A comprehensive overview of the intermediate networks is presented in **Table** \@ref(tab:tab4). These networks are structured as three-layered systems, each characterized by small-world, scale-free, or random graph architectures. In contrast to the more intricate networks featured in the **Complex Networks** dataset, the intermediate networks exhibit a comparatively simpler configuration. Specifically, each network comprises $5$ super layer nodes, $15$ middle layer nodes, and $300$ bottom layer nodes. Our primary focus in utilizing this dataset is to examine the performance of the Hierarchical Community Detection (HCD) method when applied to three-layer networks. The smaller scale of these networks facilitates a more in-depth analysis of the detected communities within the middle and upper layers of their hierarchical structures. 

We apply the HCD method to each network separately using three options for the input graph corresponding to the nodes at the observed layer of the hierarchy:

  * The input graph is the true graph
  
  *  The input graph is the correlation matrix of the simulated gene expression
  
  *  The input graph is the correlation matrix of the simulated gene expression wherein correlations weaker than 0.2 are disregarded and set to zero
  
  *  The input graph is the correlation matrix of the simulated gene expression wherein correlations weaker than 0.5 are disregarded and set to zero
  
  *  The input graph is the correlation matrix of the simulated gene expression wherein correlations weaker than 0.7 are disregarded and set to zero
  

We also explore various combinations of weighting the loss function across each of the aforementioned input graphs. In all cases, we ensure that the predicted number of communities in the middle or top levels of the hierarchy aligns with the ground truth of the simulation.

### Evaluating performance {-}

We evaluate the performance of our HCD method using three graph-based clustering metrics:

   1. **homogeneity** evaluates the degree to which each predicted community contains only data points from a single true community, indicating how well the algorithm avoids mixing different groups. Thus, homogenity tends to be high if resolved communities contain only members of the same true community.
   
   2. **completeness** assesses the extent to which all data points that belong to the same true
community are correctly assigned to a single predicted community. Thus completeness is always high if all members of the same true communities end up in the same resolved community even if several true communities are allocated together. 
   
   3. **NMI** is a weighted average of the previous two metrics. 

For each simulation, we configure the number of communities in the middle and upper layers of the hierarchy to match the true count in each layer. Then, we evaluate the community predictions of the Hierarchical Community Detection (HCD) algorithm at these levels against the actual communities using three metrics. As a baseline, we employ the Louvain method, which utilizes hierarchical graph partitioning to maximize modularity, resulting in a single set of resolved communities. These resolved communities may align with the middle, upper, or a combination of both layers in the true hierarchy. Thus, we compute the performance metrics of the communities identified by the Louvain method against the true communities at both the upper and middle levels of the hierarchy.


### Examples {-}



# Results {-}

### Comparing small world, scale free, and random graphs: small world disconnected intermediate networks {-}

In this section, we compare HCD and louvain performance on small world, scale free, and random graph networks in this simplest/easiest scenario: 3-layer intermediate networks with origin nodes simulated from $N(\mu_k, \sigma)$ distributions. These three hierarchies are the simplest in terms of the separability of the communities in the middle and top layers. A full summary of the networks in this dataset can be found in *Table* \@ref(tab:tab4). We apply HCD with the "best" parameter settings from our previous results outlined in *Report 4/15/2025* which are summarized in **Table** \@ref(tab:ex891011params). Overall, HCD performs fairly well under these parameter settings for the scale free and small world networks (**Table** \@ref(tab:example891011perf)). However, performance on the random graph network is much lower - likely due to the lack of community structure in this network (**Figure** \@ref(fig:fig)). For the scale free and small world networks, HCD performs similar to the Louvain method. Like the Lovain method, HCD is primarily capturing the top layer in the small world network and the middle layer in the scale free network. Overall, these performance values are lower than previously reported in *Report 4/15/2025*. This is may be because the data simulation procedure is different (i.e unique dists for parent nodes) and the parameter settings need to be futher tuned. In **Example 11** we should that HCD is able to achieve considerably improved performance after downweighting the clustering loss further (**Table** \@ref(tab:example891011perf)).


### Issues with loss function {-}

Our loss function combines four components: (i) MSE loss on the reconstructed graph, (ii) BCE loss on the reconstructed graph, (iii) modularity for community predictions summed across all $\ell$ hierarchical layers in the hierarchy, and (iv) the clustering loss measured as the Within Cluster Sum of squares (WCSS) for community predictions summed across all $\ell$ hierarchical layers. Components (i - ii) apply to the graph auto encoder (GATE) and aim to ensure the learned embedding respects the original node attributes and input graph. Components (iii - iv) evaluate the quality of the community predictions where loss component (iii) evalutes their quality relative to the input graph and loss component (iv) evaluates their quality with respect to the node attributes. Currently the WCSS clustering loss component is calculated on the embeddings as follows: 

\[ L_C = \sum_{\ell=1}^\mathcal{L} \frac{1}{k_{\ell-1}\cdot k_\ell} tr({\bf D}_\ell^T {\bf D}_\ell) \tag{1}\label{eq:eq1}\]

where $\ell$ is the number of hierarchical layers, $k_\ell$ is the number predicted communities in the $\ell^{th}$ hierarchical graph, and where ${\bf D}_\ell \in \mathbb{R}^{q \times k_\ell}$ is a matrix of node deviations computed as:

\[ {\bf D}_\ell =\left[{\bf \tilde X}^{(\ell-1)}\right]^T - {\bf M}_\ell{\bf P}_\ell^T \tag{2}\label{eq:eq2}\]

where ${\bf \tilde X}^{(\ell - 1)} \in \mathbb{R}^{N \times q}$ is the node embedding in the preceding hierarchical layer, ${\bf P}_\ell \in \mathbb{R}^{k_{\ell-1} \times k_\ell}$ is a matrix of community assignment probabilities, and ${\bf M}_\ell \in \mathbb{R}^{q\times k_\ell}$ is matrix of community centroids. 
One challenge with defining the clustering loss component on the model embedding is that it creates a bias which encourages the model to shift the positions of the nodes in the embedding space so that they are closer together enabling a better score on the loss function. 

To help illustrate this, we present three more examples outlined in **Table** \@ref(tab:exlossparams) where we apply HCD to a small world network with 3 layers and origin nodes simulated from different distributions. In the first example, **Clustering Loss Example 1**, we apply HCD with the usual parameters settings and the clustering loss as defined above. In this example, the clustering bias is made apparent when comparing the nodes and their true communities in both the PCA and embedding spaces. As can be seen in **Figure** \@ref(fig:examplelossfig1) the top layer communities are completely separated in the PC space and so should be easily detected, however, we can see that they are more ambiguous when viewed in the embedding space. The final predictions from this example lead to parts of two communities to be merged into a single super-community. In effect the model has cheated to get a better overall loss (**Table** \@ref(tab:exlossperf), **Figures** \@ref(fig:examplelossfig2) - \@ref(fig:examplelossfig5)). 


To address this bias, we adjust the clustering loss function given **eq 1** to compute the loss using the original node attributes. Since the node features remain unchanged through the training process the model is not encouraged to manipulate their presentations in the embedding space. To compute the loss using the original node attributes, we must know the mapping between the original $N$ nodes to their community representations in higher hierarchical layers. This can be done through a simple multiplication of the assignment probabilities from previous layers:

\[ {\bf Q}_\ell = \prod_{i = 1}^{\mathcal{\ell - 1}}{\bf P}_i\]
\[{\bf P}_1 \times {\bf P_2} \times \cdots \times {\bf P}_{\ell -1}  \]

Where the operation ${\bf Q}_\ell = {\bf P}_{\ell -1 } \otimes {\bf P}_\ell$ is the dot product between matrices ${\bf P}_{\ell -1 }$ and ${\bf P}_\ell$ where the elements in $\bf Q$ are computed as

\[q_{i,j} = {\bf p}_{\ell -1,i}^T \circ  {\bf p}_{\ell,j} = \sum_{s = 1}^{k_{\ell - 1}} p_{i,s}^{(\ell - 1)} \cdot p_{s,j}^{(\ell)}\]

for $p_{i,j}^{(\ell)} \in {\bf P}_\ell$. The vector product is akin to computing the marginal probability of assigning node $n_i$ to community $C_k$ in the $\ell^{th}$ hierarchical layer summed or all possible assignments in the previous layer(s):

\[ q_{m,k}= \sum_{m = 1}^{k_{\ell - 1}}Pr\left( n_i \in C_m^{(\ell - 1)}\right) \cdot Pr\left(n_i \in C_{k}^{(\ell)}| n_i \in C_m^{(\ell - 1)} \ \right) \]

We present the results from **Cluster Loss Example 2** which uses the above clustering loss computed on the original node features applied to the same network as in Cluster Loss Example 1. As can be seen in **Figures** \@ref(fig:examplelossfig3) - \@ref(fig:examplelossfig6) and **Table** \@ref(tab:exlossperf), using the node attributes to compute the cluster loss leads to perfect clustering performance on the top layer communities, but the middle layer communities are no longer detectable. This is possible due to a known issue with k-means like optimization in which communities that are too small or nested within larger structures are undetectable. 

In **Cluster Loss Example 3** we again apply the HCD model with the same clustering loss component as in Cluster Loss Example 1, but this time we increase the attribute reconstruction loss to see if the bias in the model's predictions were due to the attribute reconstruction have negligable influence on the total loss. As can be seen in **Table** \@ref(tab:exlossperf), this did little to improve performance. However, increasing the attribute reconstruction loss component does appear to prevent overgrouping as all five communities are detected to some degree (**Figures** \@ref(fig:examplelossfig4) - \@ref(fig:examplelossfig7)). This suggest that with further refinement of this parameter, the loss computed on the embeddings can detect the true communities and further provide some community-level information about intermediate layers in the hierarchy. 

### Using Approximate Graphs as Input {-}

In this section, compare the performance of HCD and Louvain when the input graph is an approximation of the true graph. We apply both methods to the small world, scale free, and random graph networks used in Examples 8-11. For each application, we use the correlation matrix of the node attributes wherein correlations weaker than 0.5 are disregarded and set to zero (Section *Application to Intermediate Networks*). The parameter settings are provided in **Table** \@ref(tab:ex121314params). We apply HCD with same clustering loss parameter settings as Example 11 as this settings lead to greater performance. The performance results are given in **Table** \@ref(tab:example121314perf). 



  

### future points to investigate {-}


# Tables

```{r tab1, eval=T, echo=F, message=F, warning=F}

complex_net_stats = read.csv('C:/Users/Bruin/Documents/GitHub/HGRN_repo/Simulated Hierarchies/DATA/network_statistics.csv')[,-1]

complex_net_stats$modularity_top = round(complex_net_stats$modularity_top, 3)
complex_net_stats$avg_node_degree_top = round(complex_net_stats$avg_node_degree_top, 3)
complex_net_stats$avg_connect_within_top = round(complex_net_stats$avg_connect_within_top, 3)
complex_net_stats$avg_connect_between_top = round(complex_net_stats$avg_connect_between_top, 3)
complex_net_stats$modularity_middle = round(complex_net_stats$modularity_middle, 3)
complex_net_stats$avg_node_degree_middle = round(complex_net_stats$avg_node_degree_middle, 3)
complex_net_stats$avg_connect_within_middle = round(complex_net_stats$avg_connect_within_middle, 3)
complex_net_stats$avg_connect_between_middle = round(complex_net_stats$avg_connect_between_middle, 3)




if(compile.to.pdf){
  df = rbind.data.frame(c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)'), complex_net_stats)
  kable(t(df[1:9,]), format = 'latex', digits = 2, row.names = F, col.names = c('Value', paste0('Network', c(1:8))),
                                                                                    booktabs = T,
      caption = 'Summary statistics for all small world networks in the complex networks datset')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 9)%>%column_spec(1, '6em')%>%column_spec(2:9, '4em')
}else{
  
  df = complex_net_stats
  colnames(df) = c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)')
kable(df[1:8,], format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Summary statistics for all small world networks in the complex networks datset')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}



```


\newpage
```{r tab2, eval = T, echo=F, message=F, warning=F}


if(compile.to.pdf){
  kable(t(df[c(1, 10:17),]), format = 'latex', digits = 2, row.names = F, col.names = c('Value', paste0('Network', c(1:8))),
                                                                                  booktabs = T,
     caption = 'Summary statistics for all scale free networks in the complex networks datset')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 9)%>%column_spec(1, '6em')%>%column_spec(2:9, '4em')
}else{
  kable(df[c(9:16),], format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Summary statistics for all scale free networks in the complex networks datset')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}




```


\newpage
```{r tab3, eval = T, echo=F, message=F, warning=F}


if(compile.to.pdf){
  kable(t(df[c(1, 18:25),]), format = 'latex', digits = 2, row.names = F, col.names = c('Value', paste0('Network', c(1:8))),
                                                                                    booktabs = T,
      caption = 'Summary statistics for all random graph networks in the complex networks datset')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 9)%>%column_spec(1, '6em')%>%column_spec(2:9, '4em')
}else{
  kable(df[c(17:24),], format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Summary statistics for all random graph networks in the complex networks datset')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}


```


\newpage
```{r tab4, eval = T, echo=F, message=F, warning=F, fig.cap = 'This table gives a summary of the hierarchical networks in the intermediate networks dataset where origin nodes are initialized from a normal distribution with unique means for each community.'}

inter_net_stats = read.csv('C:/Users/Bruin/Documents/GitHub/HGRN_repo/Simulated Hierarchies/DATA/Toy_examples/Intermediate_examples_unique_dist/intermediate_examples_network_statistics.csv')[,-1]

inter_net_stats$modularity_top = round(inter_net_stats$modularity_top, 3)
inter_net_stats$avg_node_degree_top = round(inter_net_stats$avg_node_degree_top, 3)
inter_net_stats$avg_connect_within_top = round(inter_net_stats$avg_connect_within_top, 3)
inter_net_stats$avg_connect_between_top = round(inter_net_stats$avg_connect_between_top, 3)
inter_net_stats$modularity_middle = round(inter_net_stats$modularity_middle, 3)
inter_net_stats$avg_node_degree_middle = round(inter_net_stats$avg_node_degree_middle, 3)
inter_net_stats$avg_connect_within_middle = round(inter_net_stats$avg_connect_within_middle, 3)
inter_net_stats$avg_connect_between_middle = round(inter_net_stats$avg_connect_between_middle, 3)





if(compile.to.pdf){
  df = rbind.data.frame(c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)'), inter_net_stats)
  kable(t(df), format = 'latex', digits = 2, row.names = F, col.names = c('Value', paste0('Network', c(1:6))),
                                                                                    booktabs = T,
      caption = 'Summary statistics for intermediate difficulty simulated networks.')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
    df = inter_net_stats
    colnames(df) = c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)')
  kable(df, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Summary statistics for intermediate difficulty simulated networks.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}




```


\newpage
```{r tab5, eval = T, echo=F, message=F, warning=F, fig.cap = 'This table gives a summary of the networks included in the simple networks dataset'}

toy_net_stats = read.csv('C:/Users/Bruin/Documents/GitHub/HGRN_repo/Simulated Hierarchies/DATA/Toy_examples/toy_examples_network_statistics.csv')[,-1]

toy_net_stats$modularity_top = round(toy_net_stats$modularity_top, 3)
toy_net_stats$avg_node_degree_top = round(toy_net_stats$avg_node_degree_top, 3)
toy_net_stats$avg_connect_within_top = round(toy_net_stats$avg_connect_within_top, 3)
toy_net_stats$avg_connect_between_top = round(toy_net_stats$avg_connect_between_top, 3)
toy_net_stats$modularity_middle = round(toy_net_stats$modularity_middle, 3)
toy_net_stats$avg_node_degree_middle = round(toy_net_stats$avg_node_degree_middle, 3)
toy_net_stats$avg_connect_within_middle = round(toy_net_stats$avg_connect_within_middle, 3)
toy_net_stats$avg_connect_between_middle = round(toy_net_stats$avg_connect_between_middle, 3)




if(compile.to.pdf){
  
  df = rbind.data.frame(c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)'), toy_net_stats)
  kable(t(df), format = 'latex', digits = 2, row.names = F, col.names = c('Value', paste0('Network', c(1:4))),
                                                                                    booktabs = T,
      caption = 'Summary statistics for simple simulated networks. These networks contain fewer than 100 nodes at the observed level and only cover small world subgraph architecture')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  
  df = toy_net_stats
  colnames(df) = c('Subgraph type','Connect. type','Layers','StDev.','Nodes per layer','Edges per layer','Subgraph prob.','Sample size', 'Modularity (top)', 'Avg. node degree top', 'Avg edges within communities (top)','Avg. edges between communities (top)', 'Modularity (middle)', 'Avg. node degree middle', 'Avg edges within communities (middle)', 'Avg edges between communities (middle)')
  kable(df, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Summary statistics for simple simulated networks. These networks contain fewer than 100 nodes at the observed level and only cover small world subgraph architecture.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}



```


\newpage
```{r tab6, echo=F, eval = F, message=F, warning=F}

grid = expand.grid(`Input Graph` = unique(tab$input_graph),
                   `Graph Recon. Loss` = c('1 = on', '0 = off'),
                   `Attr. Recon. Loss` = c('False (on)', 'True (off)'),
                   `Modularity Weight` = c('1 = on', '0 = off'),
                   `Clust. Weight` = c('1 (middle), 1 (top)', '0.1 (middle), 1e-4 (top)'))


if(compile.to.pdf){
  kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
      caption = 'Simulation settings for intermediate difficulty networks. Each row represents a single simulation scenario applied to all 6 networks in the intermediate networks dataset.')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(grid, format = 'html', digits = 2,
      row.names = F, booktabs = T, escape = F,
      caption = 'Simulation settings for intermediate difficulty networks. Each row represents a single simulation scenario applied to all 6 networks in the intermediate networks dataset.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)
}



```








```{r ex891011params, echo=F, eval = T, message=F, warning=F}

#prevpath = 'C:/Users/Bruin/Documents/GitHub/HGRN_repo/Reports/Report_4_15_2024/'
ex10.params = read.csv(paste0(figpath, 'example10_output/param_settings.csv'), row.names = 1)
ex10.params = rbind.data.frame(ex10.params, c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Small World/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', '3L-RG-DiffDist-Inter'))


ex8.params = read.csv(paste0(figpath, 'example8_output/param_settings.csv'), row.names = 1)
ex8.params = rbind.data.frame(ex8.params, c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Scale Free/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', '3L-SF-DiffDist-Inter'))


ex9.params = read.csv(paste0(figpath, 'example9_output/param_settings.csv'), row.names = 1)
ex9.params = rbind.data.frame(ex9.params,
                              c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Random Graph/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', '3L-SMW-DiffDist-Inter'))


ex11.params = read.csv(paste0(figpath, 'example11_output/param_settings.csv'), row.names = 1)
ex11.params = rbind.data.frame(ex11.params,
                              c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Small World/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', '3L-SMW-DiffDist-Inter'))


cn = colnames(ex8.params)
colnames(ex8.params) = c('Parameter', "Example 8")
ctab = cbind(ex8.params, ` ` = rep('', 17), `Example 9` = ex9.params[,-1], `Example 10` = ex10.params[,-1],
             `Example 11` = ex11.params[,-1])


if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'HCD settings for Examples 8-11.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 14)
}

```




```{r example891011perf, echo=F, eval = T, message=F, warning=F}

ex8.tab = read.csv(paste0(figpath, 'example8_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
ex9.tab = read.csv(paste0(figpath, 'example9_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
ex10.tab = read.csv(paste0(figpath, 'example10_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
ex11.tab = read.csv(paste0(figpath, 'example11_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
lbls = paste0('**', ex8.tab[,1], '**')

ex8.tab[,1] = ex9.tab[,1] = ex10.tab[,1] = ex11.tab[,1] = lbls
cn = colnames(ex8.tab)
ctab1 = rbind(c(' ', '**Example 8:**', '**Scale Free**', ''), 
             ex8.tab, 
             c('', '**Example 9:**', '**Random Graph**', ''), 
             ex9.tab) 
             
ctab2 = rbind(c('', '**Example 10:**', '**Small World**', ''),
             ex10.tab,
             c('', '**Example 11:**', '**Small World**', ''),
             ex11.tab
             )

final.ctab = cbind(ctab1, ctab2)


if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(final.ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'Performance metrics for Louvain method and HCD in Examples 8-11. For details regarding parameter settings see Examples 8-11 under section <i>Examples</i>. All networks are disconnected with 3 layers and all origin nodes are simulated from a normal distribution with unique center.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 14)
}



```




```{r exlossparams, echo=F, eval = T, message=F, warning=F}

ex1loss.params = read.csv(paste0(figpath, 'example_loss_comparisons/loss_on_embed/param_settings.csv'), row.names = 1)
ex1loss.params = rbind.data.frame(ex1loss.params, c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Small World/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', 'Special-3L-SMW-DiffDist-Inter'))
ex2loss.params = read.csv(paste0(figpath, 'example_loss_comparisons/loss_on_data/param_settings.csv'), row.names = 1)
ex2loss.params = rbind.data.frame(ex2loss.params, c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Small World/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', 'Special-3L-SMW-DiffDist-Inter'))
ex3loss.params = read.csv(paste0(figpath, 'example_loss_comparisons/loss_on_embed_boosted_xloss/param_settings.csv'), row.names = 1)
ex3loss.params = rbind.data.frame(ex3loss.params, c('Input Graph', 'True Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Small World/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', 'Special-3L-SMW-DiffDist-Inter'))


cn = colnames(ex1loss.params)
colnames(ex1loss.params) = c('Parameter', "Clustering Loss Example 1")
ctab = cbind(ex1loss.params, ` ` = rep('', 17), `Clustering Loss Example 2` = ex2loss.params[,-1],
             `Clustering Loss Example 3` = ex3loss.params[,-1])


if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'HCD settings for Loss Examples 1-3.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 14)
}

```





```{r exlossperf, echo=F, eval = T, message=F, warning=F}

ex1loss.tab = read.csv(paste0(figpath, 'example_loss_comparisons/loss_on_embed/best_iteration_toplayer_metrics.csv'), row.names = 1)
ex2loss.tab = read.csv(paste0(figpath, 'example_loss_comparisons/loss_on_data/best_iteration_toplayer_metrics.csv'), row.names = 1)
ex3loss.tab = read.csv(paste0(figpath, 'example_loss_comparisons/loss_on_embed_boosted_xloss/best_iteration_toplayer_metrics.csv'), row.names = 1)
#ex3.tab = read.csv(paste0(figpath, 'example3_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
cn = colnames(ex1loss.tab)
#ctab = cbind(ex1.tab, ` ` = rep('', 5), ex2.tab[,-1], ex3.tab[,-1])
ctab = cbind(ex1loss.tab, ` ` = rep('', 5), ex2loss.tab[,-1], ` ` = rep('', 5), ex3loss.tab[,-1])

if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'Performance metrics for Louvain method and HCD in Loss Examples 1 - 3. In these examples, two versions of the clustering loss component of HCD are compared on a small world 3 layer disconnected network with unique parent nodes (i.e simulated from different distributions). For specific details regarding the parameter settings see Loss Examples 1 - 3 under section <i>Examples</i>. The same network is used in both examples and HCD and the Louvain method are applied to the same data. In example 1, the clustering loss is computed using the node embeddings. In example 2, the clustering loss is computed using the original node attributes.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 12)%>%add_header_above(c(' ' = 1, "Clustering Loss Example 1" = 4, "Clustering Loss Example 2" = 3, "Clustering Loss Example 3" = 4))
}



```
















<!-- Examples 12-14 -->


```{r ex121314params, echo=F, eval = T, message=F, warning=F}

#prevpath = 'C:/Users/Bruin/Documents/GitHub/HGRN_repo/Reports/Report_4_15_2024/'
ex12.params = read.csv(paste0(figpath, 'example10_output/param_settings.csv'), row.names = 1)
ex12.params = rbind.data.frame(ex12.params, c('Input Graph', '0.5 Corr. Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Small World/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', '3L-RG-DiffDist-Inter'))


ex13.params = read.csv(paste0(figpath, 'example8_output/param_settings.csv'), row.names = 1)
ex13.params = rbind.data.frame(ex13.params, c('Input Graph', '0.5 Corr. Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Scale Free/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', '3L-SF-DiffDist-Inter'))


ex14.params = read.csv(paste0(figpath, 'example9_output/param_settings.csv'), row.names = 1)
ex14.params = rbind.data.frame(ex14.params,
                              c('Input Graph', '0.5 Corr. Graph'),
                              c('Layers', 3),
                              c('Network Type', 'Random Graph/Disconnected'),
                              c('Dataset', 'Intermediate Networks'),
                              c('Origin Node Dist.', '$N(\\mu_k, \\sigma)$'),
                              c('Network ID:', '3L-SMW-DiffDist-Inter'))


cn = colnames(ex12.params)
colnames(ex12.params) = c('Parameter', "Example 12")
ctab = cbind(ex12.params, ` ` = rep('', 17), `Example 13` = ex13.params[,-1], `Example 14` = ex14.params[,-1])


if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'HCD settings for Examples 12-14.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 14)
}

```





```{r example121314perf, echo=F, eval = T, message=F, warning=F}
ex12.tab = read.csv(paste0(figpath, 'example12_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
ex13.tab = read.csv(paste0(figpath, 'example13_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
ex14.tab = read.csv(paste0(figpath, 'example14_output/best_iteration_toplayer_metrics.csv'), row.names = 1)
lbls = paste0('**', ex12.tab[,1], '**')

ex12.tab[,1] = ex13.tab[,1] = ex14.tab[,1] = lbls
cn = colnames(ex12.tab)
ctab1 = rbind(c(' ', '**Example 12:**', '**Small World**', ''), 
             ex12.tab, 
             c('', '**Example 13:**', '**Scale Free**', ''), 
             ex13.tab) 

ph = as.data.frame(matrix(rep('', 5*4), nrow =5, ncol = 4))
colnames(ph) = cn
ctab2 = rbind(c('', '**Example 14:**', '**Random Graph**', ''),
             ex14.tab,
             c('', '', ''), ph)

final.ctab = cbind(ctab1, ctab2)


if(compile.to.pdf){
  # kable(grid, format = 'latex', digits = 2, row.names = F, booktabs = T,
  #     caption = '')%>%kable_styling(latex_options = c("striped", "hold_postion"),font_size = 10)%>%kable_styling(font_size = 10)%>%column_spec(1, '8em')
}else{
  kable(final.ctab, format = 'html', digits = 3,
      row.names = F, booktabs = T, escape = F,
      caption = 'Performance metrics for Louvain method and HCD in Examples 12-14. For details regarding parameter settings see Examples 12-14 under section <i>Examples</i>. All networks are disconnected with 3 layers and all origin nodes are simulated from a normal distribution with unique center.')%>%
  kable_classic(full_width = F, html_font = "Cambria")%>%kable_styling(bootstrap_options = 'striped')%>%kable_styling(font_size = 14)
}



```












# Figures 

```{r ex891011fig1, eval = T, echo = F, fig.cap='Prediction performance for Examples 8-10',fig.height=8, fig.width=12}
include_graphics(paste0(figpath,'ex8910_combined_heatmaps.png'))

```










<!-- Clustering Loss Examples -->
```{r examplelossfig1, echo=F, eval=T, fig.cap='TSNE/PCA of nodes attribute matrix. Colors indicate true community assignments at the top layer of the hierarchy', fig.height=8, fig.width=12}
include_graphics(paste0(figpath, 'example_loss_comparisons/loss_on_embed/Top Layer_tSNE_PCA_Plot.png'))

```


```{r examplelossfig2, echo = F, eval = T, fig.cap='TSNE/PCA of node embeddings at the bottleneck layer of GATE (top) and the first hierarchical layer (bottom). Colors indicate the predicted community assignments at the top layer of the hierarchy for Clustering Loss Example 1', fig.height=10, fig.width=12}
include_graphics(paste0(figpath, 'example1lossfig_embed.png'))

```

```{r examplelossfig3, echo = F, eval = T, fig.cap='TSNE/PCA of node embeddings at the bottleneck layer of GATE (top) and the first hierarchical layer (bottom). Colors indicate the predicted community assignments at the top layer of the hierarchy for Clustering Loss Example 2', fig.height=10, fig.width=12}
include_graphics(paste0(figpath, 'example2lossfig_embed.png'))

```

```{r examplelossfig4, echo = F, eval = T, fig.cap='TSNE/PCA of node embeddings at the bottleneck layer of GATE (top) and the first hierarchical layer (bottom). Colors indicate the predicted community assignments at the top layer of the hierarchy for Clustering Loss Example 3', fig.height=10, fig.width=12}
include_graphics(paste0(figpath, 'example3lossfig_embed.png'))

```


```{r examplelossfig5, eval = T, echo =F,  fig.cap='Prediction performance for Clustgering Loss Example 1', fig.height=8, fig.width=12}
include_graphics(paste0(figpath, 'example_loss_comparisons/loss_on_embed/best_iteration_34epoch_34_heatmaps.png'))

```

```{r examplelossfig6, eval = T, echo =F,  fig.cap='Prediction performance for Clustering Loss Example 2', fig.height=8, fig.width=12}
include_graphics(paste0(figpath, 'example_loss_comparisons/loss_on_data/best_iteration_99epoch_99_heatmaps.png'))

```

```{r examplelossfig7, eval = T, echo =F,  fig.cap='Prediction performance for Clustering Loss Example 2', fig.height=8, fig.width=12}
include_graphics(paste0(figpath, 'example_loss_comparisons/loss_on_embed_boosted_xloss/best_iteration_327epoch_327_heatmaps.png'))

```




```{r example121314fig1, eval = T, echo =F,  fig.cap='True and predicted adjacency matrices for examples 12 - 14', fig.height=8, fig.width=12}
include_graphics(paste0(figpath, 'Fu HCD Presentation Files/Adjacency_Heatmaps_combined.png'))

```

```{r example121314fig2, eval = T, echo =F,  fig.cap='Heatmaps showing HCD prediction performance for examples 12 - 14', fig.height=8, fig.width=12}
include_graphics(paste0(figpath, 'Fu HCD Presentation Files/heatmaps.png'))

```

```{r example121314fig3, eval = T, echo =F,  fig.cap='Correlations on the simulated data and HCD model bottleneck dimension embeddings for examples 12-14', fig.height=8, fig.width=12}
include_graphics(paste0(figpath, 'Fu HCD Presentation Files/Correlation_graphs_combined.png'))

```

```{r example121314fig4, eval = T, echo =F,  fig.cap='Loss curves for examples 12 - 14', fig.height=8, fig.width=12}
include_graphics(paste0(figpath, 'Fu HCD Presentation Files/Losses combined.png'))

```

# References
\bibliographystyle{unsrt}
	\bibliography{C:/Users/Bruin/Desktop/Research Assistantship/Thesis Proposal Defense/proposal_references.bib}

\newpage
\section*{References}
